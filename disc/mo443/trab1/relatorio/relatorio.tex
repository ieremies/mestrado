% Created 2023-04-05 Wed 22:16
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{todonotes}
\usepackage[brazil, portuges]{babel}
\usepackage{amsthm}
\usepackage{float}
\author{Ieremies Vieira da Fonseca Romero}
\date{}
\title{Trabalho 1\\\medskip
\large Introdução ao Processamento Digital de Imagem}
\hypersetup{
 pdfauthor={Ieremies Vieira da Fonseca Romero},
 pdftitle={Trabalho 1},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.6.1)}, 
 pdflang={Portuges}}
\usepackage[date=year]{biblatex}
\addbibresource{~/arq/bib.bib}
\begin{document}

\maketitle

\section*{Introdução}
\label{sec:orgb205600}
O processamento digital de imagens é uma área de estudo fundamental em Ciência da Computação, que visa o tratamento e manipulação de imagens digitais por meio de técnicas e algoritmos computacionais.
A análise e processamento de imagens digitais é uma tarefa complexa e multidisciplinar, que envolve conhecimentos em matemática, estatística, computação gráfica, processamento de sinais e outras áreas correlatas.

O objetivo deste trabalho é apresentar uma série de processamentos básicos em imagens digitais, abordando desde a leitura e escrita de imagens até operações de filtragem.
Para o desenvolvimento das operações, será empregada a vetorização de comandos, que permite processar as imagens de forma mais eficiente e rápida, através da aplicação de operações vetoriais em vez de operações matriciais.

\section*{O programa}
\label{sec:org1bb1d2f}
Neste trabalho, utilizamos as bibliotecas \texttt{numpy} 1.24.1 e OpenCV 4.7.0.72 utilizado via \texttt{cv2}.
\begin{verbatim}
import numpy as np
import cv2
\end{verbatim}

Há duas formas de utilizar o código deste projeto:
\begin{description}
\item[{script.py}] Executa todas as funções em todas as imagens e salva o seus respectivos resultados.
\item[{iterativo}] utilizando \texttt{python -i funcs.py}, é possível interagir com cada uma das funções no terminal.
\end{description}

Cada uma das questões do enúnciado é resolvido por uma função contida no arquivo \texttt{funcs.py}.
Todas as funções possuem como primeiro parâmetro a imagem sob a qual ela irá atuar.
Algumas funções possuem o segundo parâmetro, cujos significados são resumidos na tabela \ref{tab}.

\begin{table}[htbp]
\label{tab}
\centering
\begin{tabular}{ll}
Função & Significado do segundo argumento\\[0pt]
\hline
\texttt{mosaico} & ordem a ser rearrumada.\\[0pt]
\texttt{combinacao\_imagem} & segunda imagem a ser combinada.\\[0pt]
\texttt{ajuste\_brilho} & gamma a ser utilizado na operação.\\[0pt]
\texttt{quantizacao} & quantidade de níveis da imagem resultante.\\[0pt]
\texttt{planos\_bit} & qual plano queremos.\\[0pt]
\texttt{filtragem} & qual filtro aplicar.\\[0pt]
\end{tabular}
\end{table}

Para leitura e escrita de imagens, utilizamos a biblioteca \texttt{cv2} para ler e salvar imagens, como no código apresentado abaixo.
\begin{verbatim}
# Read any image to a numpy array
img_colored = cv2.imread('image.png')
# Read a grayscale image
img_gray = cv2.imread('image.png', cv2.IMREAD_GRAYSCALE)
# Save a numpy array to image file
cv.imwrite('out.png', img)
\end{verbatim}

\section*{Mosaico}
\label{sec:orgedb4092}
Para essa função recebemos tanto a imagem \texttt{img} quanto a ordem \texttt{order}.
Esta ordem é semelhante a descrita em uma ordenação dos \(16\) quadrantes, da esquerda para direita, de cima pra baixo.
Assim, o \(i\text{-ésimo}\) valor \(order_i\) indica que, na nova imagem, o quadrante \(i\) aparece no lugar do antigo quadrante \(order_i\).

No código, primeiro dividimos a imagem nos \(16\) quadrantes utilizando a função \texttt{np.split} passando como parâmetro \(4\) partes e eixos diferentes.
Depois, é necessário alterar os índices já que, em python, listas são indexadas a partir do zero.
Realizamos a conversão de ordem para coordenadas na matriz sabendo que o \(i\text{-ésimo}\) está na linha \(i // 4\) (divisão inteira) e na coluna \(i \% 4\) (resto).
Por fim, juntamos de volta os quadrantes utilizando a função \texttt{np.concatenate} e retornamos a nova imagem.
\begin{verbatim}
def mosaico(img, order):
    # Divide in 4 horizontal strips (lines)
    lines = np.split(img, 4, axis=0)
    # Divide verticaly each line in 4 pieces (squares)
    squares = [np.split(line, 4, axis=1) for line in lines]
    # Placehold for the new order of squares
    new_squares = [[0 for _ in range(4)] for _ in range(4)]
    for k in range(16):
        i = order[k] - 1  # make the order start on index zero
        # Convert the order to the coordenate in the matrix
        new_squares[k // 4][k % 4] = squares[i // 4][i % 4]
    # Recombine to form the new horizontal lines
    new_lines = [np.concatenate(new_square, axis=1) for new_square in new_squares]
    # Recombine the horizontal lines into the new image
    new_img = np.concatenate(new_lines, axis=0)
    return new_img
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_mosaico.png}
\caption{Reorganização das partes da imagem ``baboon.png'' na mesma ordenação proposta no enunciado.}
\end{figure}

\newpage
\section*{Combinação de imagem}
\label{sec:org1d7eaf0}
Utilizando a vetorização, podemos combinar as imagens \texttt{img1} e \texttt{img2}, cada uma sendo multiplicada por \(0.5\).
\begin{verbatim}
def combinacao_imagem(img1, img2):
    return 0.5 * img1 + 0.5 * img2
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_butterfly_combinacao.png}
\caption{Combinação da imagem ``baboon.png'' e ``butterfly.png''.}
\end{figure}

\newpage
\section*{Transformação de intensidade}
\label{sec:orgd15e679}
\subsection*{Negativo}
\label{sec:orgf37900a}
Podemos atingir o resultado desejado utilizando a operação \texttt{np.invert}.
\begin{verbatim}
def negativo(img):
    return np.invert(img)
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_negativo.png}
\caption{Negativo da imagem ``baboon.png''.}
\end{figure}

\subsection*{Converter para o intervalo \([100, 200]\).}
\label{sec:org84c9d55}
Para isso, entendemos que cada valor da imagem original está a uma proporção de \(0\) a \(255\).
Calculamos tal proporção e transpomos a mesma para o intervalo \(100\) a \(200\).
\begin{verbatim}
def converter_para_intervalo(img):
    return 100 + (img / 255) * 100
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_converter_para_intervalo.png}
\caption{Converção proporcional dos valores da imagem ``baboon.png'' ao intervalo \([100,200]\).}
\end{figure}

\subsection*{Linhas pares invertidas}
\label{sec:orgde29c5f}
Nesse caso, primeiro selecionamos as linhas pares, utilizando o parâmetro \texttt{step} de listas e, de forma similar, invertemo-nas utilizando \texttt{-1}.
\begin{verbatim}
def linhas_pares_invertidas(img):
    linhas_pares = img[::2]         # seleciona as linhas pares
    img[::2] = linhas_pares[:,::-1] # inverte as linhas
    return img
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_linhas_pares_invertidas.png}
\caption{Linhas pares da imagem ``baboon.png'' invertidas.}
\end{figure}

\subsection*{Reflexão de linhas}
\label{sec:orgc4b0162}
Nesse, cortamos a imagem na metade, copiamos a imagem e invertemos essa.
Por fim, salvamos a concatenação na vertical das imagens.
\begin{verbatim}
def reflexao_linhas(img):
    n, m = img.shape
    part1 = img[:m//2:]
    part2 = part1[::-1]
    return np.concatenate((part1, part2), axis=0)
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_reflexao_linhas.png}
\caption{Reflexão das linhas da imagem ``baboon.png''}
\end{figure}

\subsection*{Espelhamento vertical}
\label{sec:orgb88dbdd}
Utilizando o \texttt{step} do parâmetro de listas em python, podemos inverter a matriz.
\begin{verbatim}
def espelhamento_vertical(img):
    return img[::-1]
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_espelhamento_vertical.png}
\caption{Espelhamento vertical da imagem ``baboon.png''}
\end{figure}

\section*{Imagens coloridas}
\label{sec:orgd879570}
\subsection*{Colorida para colorida}
\label{sec:org2e95c14}
Cada pixel é representado por um vetor de três dimensões, cada uma para cada valor dos canais RGB.
Para aplicar a tranformação proposta, podemos utilizar de uma matriz para representa-la, como descrita no código pela variável \texttt{A}.
Assim, aplicamos o produto de matrizes via \texttt{np.dot} e cada pixel e substituimos o novo vetor de três dimensões como novo pixel.
Por fim, garantimos que todos os valores de canais de todos os pixels estão no intervalo de \([0, 255]\).
\begin{verbatim}
def colorida_colorida(img):
    # Set up the transformation matrix
    A = np.array([[0.393, 0.769, 0.189],
                  [0.349, 0.686, 0.168],
                  [0.272, 0.534, 0.131]])
    # Multiply each pixel by the transformation matrix
    img = np.dot(img, A)
    # Limit pixel values to the range [0, 255]
    return np.clip(img, 0, 255)
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/lena_colorida_colorida.png}
\caption{Transformação descrita aplicada à imagem ``lena.png''.}
\end{figure}

\subsection*{Coloridas para cinza}
\label{sec:org6397fd9}
Cada pixel é representado por um vetor de três dimensões, cada uma para cada valor dos canais RGB.
Para aplicar a tranformação proposta, podemos utilizar um vetor para representa-la, como descrita no código pela variável \texttt{A}.
Assim, aplicamos o produto de matrizes via \texttt{np.dot} e cada pixel e substituimos o novo pixel pelo escalar resultante.
Por fim, garantimos que os valores de todos os pixels estão no intervalo de \([0, 255]\).
\begin{verbatim}
def colorida_cinza(img):
    # Set up the transformation matrix
    A = np.array([0.2989, 0.5870, 0.1140])
    # Multiply each pixel by the transformation matrix
    img = np.dot(img, A)
    # Limit pixel values to the range [0, 255]
    return np.clip(img, 0, 255)
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/lena_colorida_cinza.png}
\caption{Transformação à escala de cinza aplicada à imagem ``lena.png''.}
\end{figure}

\section*{Ajuste de brilho}
\label{sec:org4b2c3a5}
Neste caso, recebemos a imagem e um certo valor de gamma como parâmetros.
Utilizando vetorização, aplicamos diretamente a fórmula \(B = A^{\frac{1}{\gamma}}\).
Por fim, apenas garantimos que os valores de cada pixel estão proporcionamente no intervalo \([0,255]\).
\begin{verbatim}
def ajuste_brilho(img, gamma):
    img = (img / 255) ** (1 / gamma)
    factor = 255 / np.max(img)
    return img * factor
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_ajuste_brilho_0.5.png}
\caption{Ajuste de brilho com gamma \(0.5\) aplicado à imagem ``baboon.png''.}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_ajuste_brilho_2.5.png}
\caption{Ajuste de brilho com gamma \(2.5\) aplicado à imagem ``baboon.png''.}
\end{figure}

\section*{Quantização de imagens}
\label{sec:org3c06271}
Para reduzir a quantidade de níveis de cinza à \(L\), definimos que cada valor está a uma certa proporção do intervalo de \(0\) a \(255\).
Mantemos a mesma proporção no intervalo \([0, L-1]\) e arredondamos ao nível inteiro mais próximo.
Por fim, retornamos ao formato de \(256\) mas agora com, na prática, apenas \(L\) níveis de cinza
\begin{verbatim}
def quantizacao(img, l):
    img = (img / 255) * (l - 1)
    img = np.around(img)
    return img * (256/(l-1))
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_quantizacao_2.png}
\caption{Quantização da imagem ``baboon.png'' em \(2\) níveis.}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_quantizacao_16.png}
\caption{Quantização da imagem ``baboon.png'' em \(16\) níveis.}
\end{figure}

\section*{Planos de bits}
\label{sec:org90aafa3}
Para extrairmos cada plano de bit, como definido no enunciado, precisamos pegar o \(i-text{ésimo}\) bit da esquerda para direita.
Assim, o \(i\) plano, fazemos \texttt{(img >> i) \& 1} e salvamos cada um desses planos numa lista.
Na hora de salvar a imagem, precisamos multiplicar por \(255\), já que cada plano de bit é uma array de \(0\) e \(1\).
\begin{verbatim}
def planos_bit(img, plano):
    bit_planes = [np.uint8((img >> bit) & 1) for bit in range(8)]
    return bit_planes[plano] * 255
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_planos_bit_0.png}
\caption{Primeiro plano de bits da imagem ``baboon.png''.}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_planos_bit_4.png}
\caption{Quinto plano de bits da imagem ``baboon.png''.}
\end{figure}

\newpage
\section*{Filtragem de imagens}
\label{sec:orgd34e85b}
\begin{verbatim}
# Definição das matrizes
h1 = np.asarray([[0, 0, -1, 0, 0],
                 [0, -1, -2, -1, 0],
                 [-1, -2, 16, -2, -1],
                 [0, -1, -2, -1, 0],
                 [0, 0, -1, 0, 0]])
h2 = np.asarray([[1, 4, 6, 4, 1],
                 [4, 16, 24, 16, 4],
                 [6, 24, 36, 24, 6],
                 [4, 16, 24, 16, 4],
                 [1, 4, 6, 4, 1]])
h2 = h2 / 256
h3 = np.asarray([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
h4 = np.asarray([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])
h5 = np.asarray([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])
h6 = np.asarray([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9
h7 = np.asarray([[-1, -1, 2], [-1, 2, -1], [2, -1, -1]])
h8 = np.asarray([[2, -1, -1], [-1, 2, -1], [-1, -1, 2]])
h9 = np.identity(9) / 9
h10 = np.asarray([[-1, -1, -1, -1, -1],
                  [-1, 2, 2, 2, -1],
                  [-1, 2, 8, 2, -1],
                  [-1, 2, 2, 2, -1],
                  [-1, -1, -1, -1, -1]])
h10 = h10 / 8
h11 = np.asarray([[1, -1, 0], [-1, 0, 1], [0, 1, 1]])
\end{verbatim}

Para cada filtro, definimos um kernel, uma matriz que representa nosso filtro.
Para aplicarmos o filtro, passamos a imagem bem como o filtro para a função \texttt{cv2.filter2D}.
Vale a pena ressaltar o argumento \texttt{-1} da função, este especifica que a saída deve ter a mesma profundidade que a entrada.

Outro fato interessante de comentar é sobre as decisões de ``padding''.
Quando aplicamos um filtro como os descritos aqui, precisamos decidir o que fazer nos pixels de borda, já que estes não possuem todos os vizinhos como os demais pixels.
A função \texttt{cv2.filter2D} aplica o chamado ``zero-padding'', na qual são adicionados zeros às bordas conforme necessário.
\begin{verbatim}
def filtragem(img, h):
    return cv2.filter2D(img, -1, h)
\end{verbatim}

Por questões de espaço, neste relatório iremos reproduzir os resultados de alguns filtros.
Todos os resultados estão disponíveis na pasta \texttt{out}.

\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_filtro_h3.png}
\caption{Filtro \(h_3\) aplicado à imagem ``baboon.png''.}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_filtro_h4.png}
\caption{Filtro \(h_4\) aplicado à imagem ``baboon.png''.}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_filtro_h9.png}
\caption{Filtro \(h_9\) aplicado à imagem ``baboon.png''.}
\end{figure}

Após executar os filtros observamos os seguintes efeitos de cada um:
\begin{description}
\item[{h1}] passa-alta que realça as bordas.
\item[{h2}] de suavização (blur) que reduz o ruído.
\item[{h3}] detecta bordas no sentido horizontal.
\item[{h4}] detecta bordas no sentido vertical.
\item[{h5}] realça as bordas.
\item[{h6}] de suavização (blur) que reduz o ruído e as características.
\item[{h7}] detecta bordas diagonais.
\item[{h8}] detecta bordas diagonais.
\item[{h9}] de suavização (blur) diagonalmente.
\item[{h10}] de nitidez que realça as características.
\item[{h11}] aumenta o brilho (efeito de gloom).
\end{description}

Por fim, como sugerido no enunciado, podemos combinar o kernel \(h3\) com o \(h4\).
Utilizamos as funções \texttt{np.square} e \texttt{np.sqrt} para realizar as operações aritméticas vetorizadas.
Vemos que a combinação de dois filtros que detectavam bordas em sentidos diferentes resultam em um bom filtro para detectar bordas em ambos.
\begin{verbatim}
def filtragem_h3_h4(img):
    img = img.astype(np.float32)
    res = np.square(filtragem(img, h3))
    res += np.square(filtragem(img, h4))
    res = np.sqrt(res)
    return res
\end{verbatim}
\begin{figure}[H]
\centering
\includegraphics[width=200]{./out/baboon_filtragem_h3_h4.png}
\caption{Resultado do filtro \(h_3\) combinado com o resultado do filtro \(h_4\) na imagem ``baboon.png''}
\end{figure}
\end{document}